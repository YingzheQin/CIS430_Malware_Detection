import data_setup, engine, utils
import torchvision
from torchvision.transforms import v2
import torch
from torch import nn
from torch.utils.tensorboard.writer import SummaryWriter
from datetime import datetime
from pathlib import Path

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

train_dir = '4_percent_image_data/train'
test_dir = '4_percent_image_data/test'

BATCH_SIZE = 32
LEARNING_RATE = 0.001

# ToTensor() is deprecated, use the combination of v2.ToImage() and v2.v2.ToDtype(torch.float32, scale=True) instead.
simple_transform = v2.Compose([
    v2.Resize((224, 224)),
    v2.ToImage(),  # make sure the input data is interpreted as image
    v2.ToDtype(torch.float32, scale=True),  # turn pixel values into tensors and scaling to (0, 1)
    v2.Normalize(mean=[0.485, 0.456, 0.406],
                 std=[0.229, 0.224, 0.225])  # same distribution with ImageNet
])

train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir=train_dir,
    test_dir=test_dir,
    transform=simple_transform,
    batch_size=BATCH_SIZE
)


def create_writer(experiment_name: str,
                  model_name: str,
                  extra: str,
                  ) -> SummaryWriter():
    """
    Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.
    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.
    Where timestamp is the current date in YYYY-MM-DD format.

    Args:
        experiment_name: Name of experiment
        model_name: Name of model
        extra:  Anything extra to add to the directory. Defaults to None.

    Returns: torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.

    Example usage:
    # Create a writer saving to "runs/2023-11-20/data_10_percent/effnetb2/5_epochs/"
    writer = create_writer(experiment_name="data_10_percent",
                           model_name="effnetb2",
                           extra="5_epochs")
    # The above is the same as:
    writer = SummaryWriter(log_dir="runs/2023-11-20/data_10_percent/effnetb2/5_epochs/")
    """
    timestamp = datetime.now().strftime('%Y-%m-%d')
    log_dir = Path('runs') / timestamp / experiment_name / model_name
    if extra:
        log_dir /= extra
    print(f"[INFO] Created SummaryWriter, saving to: {log_dir}...")
    return SummaryWriter(log_dir=str(log_dir))


def create_densenet121():
    """

    Create a densenet_121 feature extractor

    Returns: a pretrained densenet 121 model with a classifier adapted to our dataset.

    """
    weights = torchvision.models.DenseNet121_Weights.DEFAULT  # DEFAULT means the best available
    model = torchvision.models.densenet121(weights=weights).to(device)

    # Freeze all feature extraction layer
    for param in model.features.parameters():
        param.requires_grad = False

    # Replace the last layer
    model.classifier = nn.Sequential(
        nn.Linear(in_features=1024, out_features=10)  # We have 10 classes in our dataset
    ).to(device)

    model.name = 'densenet121'
    return model


def create_densenet161():
    """

    Create a densenet_161 feature extractor

    Returns: a pretrained densenet 161 model with a classifier adapted to our dataset.

    """
    weights = torchvision.models.DenseNet161_Weights.DEFAULT  # DEFAULT means the best available
    model = torchvision.models.densenet161(weights=weights).to(device)

    # Freeze all feature extraction layer
    for param in model.features.parameters():
        param.requires_grad = False

    # Replace the last layer
    model.classifier = nn.Sequential(
        nn.Linear(in_features=2208, out_features=10)
    ).to(device)

    model.name = 'densenet121'
    return model


# Start the experiment by two models, and two epoch numbers.
num_epochs = [5, 10]
models = ['densenet121', 'densenet161']

torch.manual_seed(42)
torch.cuda.manual_seed(42)
experiment_number = 0
for epochs in num_epochs:
    for model_name in models:
        experiment_number += 1
        print(f'[INFO] experiment number: {experiment_number}')
        print(f'[INFO] epochs : {epochs}')
        print(f'[INFO] model: {model_name}')
        if model_name == 'densenet121':
            model = create_densenet121()
        else:
            model = create_densenet161()

        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)

        engine.train(model=model,
                     train_dataloader=train_dataloader,
                     test_dataloader=test_dataloader,
                     loss_fn=criterion,
                     optimizer=optimizer,
                     epochs=epochs,
                     writer=create_writer(experiment_name='malware_detection_1.0',
                                          model_name=model_name,
                                          extra=f'{epochs} epochs'),
                     device=device)

        # create a path to save each model
        model_save_path = f'malware_detection_1.0_{model_name}_{epochs}_epochs.pth'
        utils.save_model(model=model,
                         target_dir='models',
                         model_name=model_save_path)
        print("-" * 50 + "\n")
